import streamlit as st
from document_store import NewsDocumentStore
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
from langchain.callbacks.base import BaseCallbackHandler
import os
from dotenv import load_dotenv
import requests
import re
from bs4 import BeautifulSoup as bs

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class StreamHandler(BaseCallbackHandler):
    def __init__(self, container, initial_text=""):
        self.container = container
        self.text = initial_text
        self.message_placeholder = container.empty()

    def on_llm_new_token(self, token: str, **kwargs):
        self.text += token
        self.message_placeholder.markdown(self.text)

def initialize_session_state():
    """Streamlit ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    if 'doc_store' not in st.session_state:
        # ê¸°ì¡´ collectionì„ ì‚¬ìš©í•˜ì—¬ NewsDocumentStore ì´ˆê¸°í™”
        st.session_state.doc_store = NewsDocumentStore.from_existing("news_documents")
    
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
        
    if 'llm' not in st.session_state:
        st.session_state.llm = ChatOpenAI(
            model_name="gpt-4o-mini",
            temperature=0.7,
            streaming=True  # ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”
        )

def search_documents(query: str, k: int = 3):
    """ë¬¸ì„œ ê²€ìƒ‰ í•¨ìˆ˜"""
    try:
        return st.session_state.doc_store.similarity_search(query, k=k)
    except Exception as e:
        st.error(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return []

def extract_company(query: str) -> str:
    """GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„±"""
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    system_prompt = """ë‹¹ì‹ ì„ ì‚¬ìš©ìì˜ ì…ë ¥ì—ì„œ íšŒì‚¬ëª…ì„ ì¶”ì¶œí•´ì•¼ í•©ë‹ˆë‹¤. ì ì ˆí•œ íšŒì‚¬ëª…ì„ ì¶”ì¶œí•˜ì—¬ íšŒì‚¬ëª…ë§Œ ë‹µë³€í•˜ì„¸ìš”."""
    

    # ë©”ì‹œì§€ êµ¬ì„±
    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=f"ì…ë ¥: {query}")
    ]
    
    try:
        # GPTë¡œ ìŠ¤íŠ¸ë¦¬ë° ë‹µë³€ ìƒì„± (invoke ë©”ì†Œë“œ ì‚¬ìš©)
        response = st.session_state.llm.invoke(
            messages
        )
        return response.content
    
    except Exception as e:
        st.error(f"íšŒì‚¬ëª… ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return "ì£„ì†¡í•©ë‹ˆë‹¤. íšŒì‚¬ëª… ì¶”ì¶œ ì¤‘ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

def clean(text):
    i = text.find('ê¸€ììˆ˜')
    text = text[:i]
    return text.strip()


def get_company_recruit(search_keyword):
    base_url = "https://www.jobkorea.co.kr/starter/PassAssay"
    headers={'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36'}
    response = requests.get(f"{base_url}?schTxt={search_keyword}", headers=headers)
    soup = bs(response.text,'html.parser')
    items = []
    for _, item in enumerate(soup.select('#container > div.stContainer > div.starListsWrap.ctTarget > ul > li')):
        items.append(item.select(f'.txBx'))
    
    soup_ans_list = []
    if not items[0]:
        return None
    for item in items:
        item_id = re.findall("\d{6}", item[0].select('a')[0].attrs['href'])[0]
        response_ans = requests.get(f"{base_url}/View/{item_id}?Page=1&OrderBy=0&schTxt={search_keyword}&FavorCo_Stat=0&Pass_An_Stat=0", headers=headers)
        soup_ans_list.append(bs(response_ans.text,'html.parser'))

    q_list = []
    a_list = []
    for soup_ans in soup_ans_list:
        q_list += [q.select_one('.tx').text for q in soup_ans.select('#container > div.stContainer > div.selfQnaWrap > dl > dt')]
        a_list += [clean(a.select_one('.tx').text) for a in soup_ans.select('#container > div.stContainer > div.selfQnaWrap > dl > dd')]
    
    qna = ""
    for q, a in zip(q_list, a_list):
        qna += f"ì§ˆë¬¸: {q} \në‹µë³€: {a}\n"
    
    return qna

def generate_answer(query: str, relevant_docs: list, stream_handler) -> str:
    """GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„±"""
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±

    company_name = extract_company(query).replace(' ', '')
    print(company_name)
    company_qna = get_company_recruit(company_name)
    # print(company_qna)

    system_prompt = """ë‹¹ì‹ ì€ êµ¬ì§ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ê¸°ì—…ì˜ ì •ë³´ë¥¼ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
    ì œê³µëœ ë¬¸ì„œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•˜ë˜, ë¬¸ì„œ ë‚´ìš©ì„ ì¸ìš©í•©ë‹ˆë‹¤.
    QnAëŠ” ì´ë¯¸ ì·¨ì—…ì„ ì„±ê³µí•œ ì‚¬ìš©ìë“¤ì˜ ìê¸°ì†Œê°œì„œì…ë‹ˆë‹¤. ë¶„ì„í•´ì„œ í•¨ê»˜ ì œê³µí•˜ì„¸ìš”.
    ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ë©°, ì·¨ì—…ì„ ìœ„í•œ ìê¸°ì†Œê°œì„œ/ë©´ì ‘ì— ë„ì›€ì´ ë  ë‚´ìš© ì •í™•í•˜ê³  ìì„¸í•˜ê²Œ ì•Œë ¤ì£¼ì„¸ìš”.
    user: {company}
    you: {company}ëŠ” {context}í•œ ìƒí™©ì…ë‹ˆë‹¤.
        **ì·¨ì—… ì¤€ë¹„ë¥¼ ìœ„í•œ íŒ**: {company}ì™€ ê°™ì€ ê¸°ì—…ì— ì§€ì›í•  ë•ŒëŠ” {recommend} í•œ ê²ƒë“¤ì„ ì‹ ê²½ì“°ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
        **ì„±ê³µ ì‚¬ë¡€**:
        {q}ì— ëŒ€í•œ ë¬¸í•­ì—,
        í•©ê²©ìë“¤ì€ {a}ë¼ê³  ë‹µí–ˆìŠµë‹ˆë‹¤.
        ê·¸ëŸ¬ë¯€ë¡œ ë‹¹ì‹ ì€ {solution}ì„ ì—¼ë‘ì— ë‘ê³  ì¤€ë¹„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."""
    
    # ê´€ë ¨ ë¬¸ì„œ ì •ë³´ êµ¬ì„±
    if company_qna is None:
        context = f"ê´€ë ¨ ë¬¸ì„œ ì •ë³´:\n"
    else:
        context = f"QnA: {company_qna}\nê´€ë ¨ ë¬¸ì„œ ì •ë³´:\n"

    for i, doc in enumerate(relevant_docs, 1):
        context += f"{i}. {doc['content']}\n"
    
    # ë©”ì‹œì§€ êµ¬ì„±
    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=f"ë‹¤ìŒ ë¬¸ì„œ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ê¸°ì—…ì— ëŒ€í•œ ìµœì‹  ì •ë³´ì™€ ë™í–¥ì„ ìš”ì•½ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n\n{context}\n\nì§ˆë¬¸: {query}")
    ]
    
    try:
        # GPTë¡œ ìŠ¤íŠ¸ë¦¬ë° ë‹µë³€ ìƒì„± (invoke ë©”ì†Œë“œ ì‚¬ìš©)
        response = st.session_state.llm(
            messages,
            callbacks=[stream_handler]
        )
        return response.content
    except Exception as e:
        st.error(f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

def main():
    st.set_page_config(
        page_title="AI ì±—ë´‡",
        page_icon="ğŸ¤–",
        layout="wide"
    )
    
    initialize_session_state()
    
    # ë©”ì¸ ì±„íŒ… ì˜ì—­ê³¼ ì‚¬ì´ë“œë°” ë ˆì´ì•„ì›ƒ ì„¤ì •
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.title("ChuiBBOt")
        
        # ì±„íŒ… ì»¨í…Œì´ë„ˆ ìƒì„±
        chat_container = st.container()
        with chat_container:
            # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
            for message in st.session_state.chat_history:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])
        
        # ì‚¬ìš©ì ì…ë ¥ ì˜ì—­
        if question := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
            # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
            with chat_container:
                with st.chat_message("user"):
                    st.markdown(question)
                st.session_state.chat_history.append({"role": "user", "content": question})
                
                # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
                with st.spinner("ê´€ë ¨ ì •ë³´ ê²€ìƒ‰ ì¤‘..."):
                    results = search_documents(question)

                # ì‚¬ì´ë“œë°” ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ ìƒíƒœ ì €ì¥
                st.session_state.latest_results = results
                
                # GPT ë‹µë³€ ìƒì„± ë° í‘œì‹œ
                with st.chat_message("assistant"):
                    stream_handler = StreamHandler(st.empty())
                    answer = generate_answer(question, results, stream_handler)
                    st.session_state.chat_history.append({"role": "assistant", "content": answer})
            
    # ì‚¬ì´ë“œë°”: ê´€ë ¨ ë¬¸ì„œ ì •ë³´ í‘œì‹œ
    with col2:
        st.sidebar.title("ğŸ“‘ ê´€ë ¨ ë¬¸ì„œ")
        # í˜„ì¬ ì§ˆë¬¸ í‘œì‹œ
        if 'chat_history' in st.session_state and st.session_state.chat_history:
            last_user_message = next((msg for msg in reversed(st.session_state.chat_history) 
                                    if msg["role"] == "user"), None)
            if last_user_message:
                st.sidebar.markdown("**í˜„ì¬ ì§ˆë¬¸:**")
                st.sidebar.info(last_user_message["content"])
                
        # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
        if 'latest_results' in st.session_state and st.session_state.latest_results:
            for i, result in enumerate(st.session_state.latest_results, 1):
                with st.sidebar.expander(f"ê´€ë ¨ ë¬¸ì„œ {i} (ìœ ì‚¬ë„: {result['similarity']:.2%})"):
                    st.markdown("**ë‚´ìš©:**")
                    st.write(result['content'][:300] + "..." if len(result['content']) > 300 else result['content'])
                    st.markdown("**ë©”íƒ€ë°ì´í„°:**")
                    for key, value in result['metadata'].items():
                        st.write(f"- {key}: {value}")
        else:
            st.sidebar.info("ê´€ë ¨ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
        if st.sidebar.button("ëŒ€í™” ë‚´ìš© ì´ˆê¸°í™”", type="secondary"):
            st.session_state.chat_history = []
            if 'latest_results' in st.session_state:
                del st.session_state.latest_results
            st.rerun()

if __name__ == "__main__":
    main()